{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nayk1bgPSfO9"
      },
      "source": [
        "#Titanic Survival Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1879S41cSm0Q"
      },
      "source": [
        "###You will use the Titanic Survival Dataset to build a classification model to predict whether a passenger survived the sinking of the Titanic, based on attributes of each passenger in the data set.You'll start with building a Random Forest Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoKB_uMBTRIt"
      },
      "source": [
        "##Data Collection and Understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rdOS7spU10g"
      },
      "source": [
        "###Dataset: https://www.kaggle.com/datasets/yasserh/titanic-dataset/discussion?sort=hotness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMeD-ByH1gaZ"
      },
      "source": [
        "###Upload Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tT9jhGAJSlBW",
        "outputId": "736caa72-8b58-481a-a339-62f69f80b372"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-12035b2f-d36f-4353-a726-879680d2fe11\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-12035b2f-d36f-4353-a726-879680d2fe11\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQvUVOQP1nWv"
      },
      "source": [
        "###Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNHGQCdE1t9C"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"Titanic-Dataset.csv\")\n",
        "\n",
        "print(\" Dataset Loaded Successfully\")\n",
        "print(\"Shape of dataset:\", df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-zZIx3m2Ges"
      },
      "source": [
        "###Column Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VabVJAv22On4"
      },
      "outputs": [],
      "source": [
        "#Shows each column, datatype, and missing values count.\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGpxe_Rm2Usk"
      },
      "source": [
        "###Column Descriptions\n",
        "\n",
        "Make a small table of column meanings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm4VWY3z2fWC"
      },
      "outputs": [],
      "source": [
        "#This table explains dataset features\n",
        "col_descriptions = {\n",
        "    \"PassengerId\": \"Unique ID of each passenger\",\n",
        "    \"Survived\": \"Target variable (0 = Did not survive, 1 = Survived)\",\n",
        "    \"Pclass\": \"Passenger class (1 = 1st, 2 = 2nd, 3 = 3rd)\",\n",
        "    \"Name\": \"Passenger’s full name\",\n",
        "    \"Sex\": \"Gender\",\n",
        "    \"Age\": \"Age in years\",\n",
        "    \"SibSp\": \"Number of siblings/spouses aboard\",\n",
        "    \"Parch\": \"Number of parents/children aboard\",\n",
        "    \"Ticket\": \"Ticket number\",\n",
        "    \"Fare\": \"Fare paid\",\n",
        "    \"Cabin\": \"Cabin number (many missing)\",\n",
        "    \"Embarked\": \"Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\"\n",
        "}\n",
        "\n",
        "pd.DataFrame.from_dict(col_descriptions, orient=\"index\", columns=[\"Description\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0knZvaIC3Evr"
      },
      "source": [
        "###Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOwDHXHG3JgB"
      },
      "outputs": [],
      "source": [
        "#Identify which columns need cleaning (Age, Cabin, Embarked).\n",
        "df.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaUrH2D-3TNI"
      },
      "source": [
        "###Summary Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5diHyFaY3eYh"
      },
      "outputs": [],
      "source": [
        "#Mean, min, max, std for numerical features\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3X4Acdf_Lq8"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpHHqfMl3xdR"
      },
      "source": [
        "###Short Report\n",
        "\n",
        "\n",
        "\n",
        "✔ Dataset shape: 891 × 12\n",
        "\n",
        "✔ Target variable: Survived\n",
        "\n",
        "✔ Missing values: Age (177), Cabin (687), Embarked (2)\n",
        "\n",
        "✔ Numerical features: Age, Fare, SibSp, Parch\n",
        "\n",
        "✔ Categorical features: Sex, Embarked, Pclass, Cabin\n",
        "\n",
        "✔ Insights: ~38% survived"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRiwZQJ3_aeT"
      },
      "source": [
        "# 1. Handle Missing Values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2DH6oXE_g7X"
      },
      "outputs": [],
      "source": [
        "df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].median())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuQenkMr_xny"
      },
      "outputs": [],
      "source": [
        "# Cabin: too many missing values → create a new feature 'HasCabin' (1 if cabin present, 0 otherwise)\n",
        "if \"Cabin\" in df.columns:\n",
        " df[\"HasCabin\"] = df[\"Cabin\"].notnull().astype(int)\n",
        " df.drop(\"Cabin\", axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hNmlA26_z-0"
      },
      "outputs": [],
      "source": [
        "# Embarked: fill missing with mode (most frequent value)\n",
        "df[\"Embarked\"] = df[\"Embarked\"].fillna(df[\"Embarked\"].mode()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4lMLDyYBZtn"
      },
      "outputs": [],
      "source": [
        "print(\"Missing values after handling:\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_zv7yoACV_9"
      },
      "source": [
        "2. Detect and Handle Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNiOYwoJCYqk"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_ixBlmYCmNZ"
      },
      "outputs": [],
      "source": [
        "# Define function for capping outliers using IQR method\n",
        "def cap_outliers(series):\n",
        "    Q1 = series.quantile(0.25)\n",
        "    Q3 = series.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "    return np.where(series < lower, lower, np.where(series > upper, upper, series))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSOINLK9CuRm"
      },
      "outputs": [],
      "source": [
        "df[\"Fare\"] = cap_outliers(df[\"Fare\"])\n",
        "df[\"Age\"] = cap_outliers(df[\"Age\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu5xkbDlC0Ro"
      },
      "source": [
        " 3. Convert Categorical Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xK7HwSMYC3Vv"
      },
      "outputs": [],
      "source": [
        "df[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\": 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMbNcKyNDH1l"
      },
      "outputs": [],
      "source": [
        "# Embarked: One-Hot Encoding (C, Q, S)\n",
        "df = pd.get_dummies(df, columns=[\"Embarked\"], drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2G6CkLbjDL2J"
      },
      "outputs": [],
      "source": [
        "# Drop irrelevant columns: Name, Ticket, PassengerId\n",
        "df.drop([\"Name\", \"Ticket\", \"PassengerId\"], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4skhstkqDc8M"
      },
      "outputs": [],
      "source": [
        "print(\"\\nFinal cleaned dataset shape:\", df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeppXJe6uMLC"
      },
      "source": [
        "# **Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thQaqgguuRvX"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "df_viz = df.copy()\n",
        "\n",
        "df_viz['Sex'] = df_viz['Sex'].map({0: 'Male', 1: 'Female'})\n",
        "\n",
        "df_viz['AgeGroup'] = pd.cut(df_viz['Age'], bins=[0, 12, 18, 35, 60, 100], labels=['Child', 'Teen', 'Adult', 'Mid-Aged', 'Senior'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFahw8OwvUVC"
      },
      "source": [
        "Survival rate by Gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1j2btOLavRe-"
      },
      "outputs": [],
      "source": [
        "\n",
        "gender_survival = df_viz.groupby('Sex')['Survived'].mean() * 100\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "ax = sns.barplot(x=gender_survival.index, y=gender_survival.values, palette='viridis')\n",
        "plt.title('Survival Rate by Gender', fontsize=16, fontweight='bold')\n",
        "plt.ylabel('Survival Rate (%)')\n",
        "plt.xlabel('Gender')\n",
        "\n",
        "\n",
        "for i, v in enumerate(gender_survival.values):\n",
        "    ax.text(i, v + 1, f'{v:.1f}%', ha='center', fontweight='bold')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzgmgD7VxUxR"
      },
      "source": [
        "This chart shows the survival rate by gender in which Female have more survival rate of 74.2 % aa compared to males having survival rate of 18.9%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETuiKqrvxvCT"
      },
      "source": [
        "# **Survival Rate by Passenger Class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2V5d9SMPvgIP"
      },
      "outputs": [],
      "source": [
        "\n",
        "class_survival = df_viz.groupby('Pclass')['Survived'].mean() * 100\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "ax = sns.barplot(x=class_survival.index, y=class_survival.values, palette='magma')\n",
        "plt.title('Survival Rate by Passenger Class', fontsize=16, fontweight='bold')\n",
        "plt.ylabel('Survival Rate (%)')\n",
        "plt.xlabel('Passenger Class')\n",
        "\n",
        "for i, v in enumerate(class_survival.values):\n",
        "    ax.text(i, v + 1, f'{v:.1f}%', ha='center', fontweight='bold')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDJrM1VKxzPo"
      },
      "source": [
        "This bar plot shows survival rate by passenger class. The results show that class 1 has the highest rate of 63.0 % , followed by class 2 with 47.3% survival rate and then class 3 having lowest survival rate of 24.2 %."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCg1cQkkvtQP"
      },
      "source": [
        "Srvival rate by Age Group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KhnxNxLvp7u"
      },
      "outputs": [],
      "source": [
        "\n",
        "agegroup_survival = df_viz.groupby('AgeGroup')['Survived'].mean() * 100\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "ax = sns.barplot(x=agegroup_survival.index, y=agegroup_survival.values, palette='plasma')\n",
        "plt.title('Survival Rate by Age Group', fontsize=16, fontweight='bold')\n",
        "plt.ylabel('Survival Rate (%)')\n",
        "plt.xlabel('Age Group')\n",
        "\n",
        "for i, v in enumerate(agegroup_survival.values):\n",
        "    ax.text(i, v + 1, f'{v:.1f}%', ha='center', fontweight='bold')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQtBArtYyQx1"
      },
      "source": [
        "This bar plot shows survival rate of passenegers according to their group which shows that children have the highest survival rate ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REGhEgwJv3ES"
      },
      "source": [
        "Histogram of Age Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMuUJG--vz5a"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(df_viz['Age'].dropna(), kde=True, bins=30, color='skyblue')\n",
        "plt.title('Distribution of Age on the Titanic', fontsize=16)\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Count')\n",
        "plt.axvline(df_viz['Age'].mean(), color='red', linestyle='--', label=f'Mean Age: {df_viz[\"Age\"].mean():.1f}')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTKTP1-ZyzWV"
      },
      "source": [
        "This histogram shows the age distribution of passengers and the results highlight that most of the peopel are around 25 to 30 and the peak of histogram lies at 30 showing mean age of passengers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7sBJCk5v-gu"
      },
      "source": [
        "Bos Plot of Fare by Passenger Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bbkZzH9v7fH"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(x='Pclass', y='Fare', data=df_viz, palette='magma')\n",
        "plt.title('Fare Distribution by Passenger Class', fontsize=16)\n",
        "plt.yscale('log')\n",
        "plt.ylabel('Fare (Log Scale)')\n",
        "plt.xlabel('Passenger Class')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tXHxJmA1Wef"
      },
      "source": [
        "First class was  more expensive than second or third class\n",
        "\n",
        "Second and third class tickets were more affordable and had less variation in their prices compared to first class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zB8jOmDexLr0"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "survived_sex = pd.crosstab(df_viz['Sex'], df_viz['Survived'])\n",
        "\n",
        "survived_sex.plot(kind='bar', stacked=True, color=['#e74c3c', '#2ecc71'], figsize=(8, 5))\n",
        "plt.title('Survival Count by Gender', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('Number of Passengers')\n",
        "plt.legend(['Did Not Survive', 'Survived'], title='Survival Outcome')\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPceGiEhwN1s"
      },
      "source": [
        "Correlation Analysis with survival"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjdeeO5EwFft"
      },
      "outputs": [],
      "source": [
        "\n",
        "corr_matrix = df.corr()\n",
        "plt.figure(figsize=(10, 6))\n",
        "mask = np.zeros_like(corr_matrix)\n",
        "mask[-1, :] = True\n",
        "\n",
        "sns.heatmap(corr_matrix[['Survived']].sort_values(by='Survived', ascending=False).T,\n",
        "            annot=True, cmap='RdBu_r', center=0, vmin=-1, vmax=1)\n",
        "plt.title('Feature Correlation with Survival (Target Variable)\\n', fontsize=16, fontweight='bold')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15r0GnERwxIp"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.set(font_scale=1.1)\n",
        "\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "\n",
        "\n",
        "heatmap = sns.heatmap(corr_matrix,\n",
        "                      mask=mask,\n",
        "                      annot=True,\n",
        "                      fmt='.2f',\n",
        "                      cmap='RdBu_r',\n",
        "                      center=0,\n",
        "                      square=True,\n",
        "                      cbar_kws={\"shrink\": .8})\n",
        "\n",
        "\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.title('Full Correlation Matrix Heatmap of Titanic Dataset Features\\n', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugWfO1EXz5iK"
      },
      "source": [
        "The \"Sex\" feature has a strong positive correlation with \"Survived\" (0.54)\n",
        "which shows that female passengers were more likely to survive.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The \"Fare\" feature shows a strong negative correlation with \"Pclass\" (-0.72) that indicates that passengers in lower classes paid less for their tickets.  \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\"HasCabin\" also have a strong positive correlation with survival rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRNa0wdg5mVO"
      },
      "source": [
        "# **Module-3 Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4msz-oPyG_HW"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "X = df.drop(\"Survived\", axis=1)\n",
        "y = df[\"Survived\"]\n",
        "\n",
        "categorical_features = [\"Sex\", \"Pclass\", \"HasCabin\", \"Embarked_Q\", \"Embarked_S\"]  # from your cleaned df\n",
        "numerical_features = [col for col in X.columns if col not in categorical_features]\n",
        "\n",
        "print(\"Categorical features:\", categorical_features)\n",
        "print(\"Numerical features:\", numerical_features)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPHwg6j52b_p"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "df[\"Sex\"] = le.fit_transform(df[\"Sex\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QiK20kI20pM"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "categorical_cols = [\"Sex\", \"Embarked\"]\n",
        "numerical_cols = [col for col in df.columns if col not in [\"Survived\", \"Sex\", \"Embarked\"]]\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", \"passthrough\", numerical_cols),\n",
        "        (\"cat\", OneHotEncoder(drop=\"first\"), categorical_cols)\n",
        "    ]\n",
        ")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQtQ72NYHkB1"
      },
      "outputs": [],
      "source": [
        "# Extract Title from Name\n",
        "df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "\n",
        "# Replace rare titles into one category\n",
        "df['Title'] = df['Title'].replace(\n",
        "    ['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major',\n",
        "     'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare'\n",
        ")\n",
        "\n",
        "# Merge similar titles\n",
        "df['Title'] = df['Title'].replace({'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs'})\n",
        "\n",
        "# Check distribution of titles\n",
        "print(df['Title'].value_counts())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBOfdXCuINlJ"
      },
      "outputs": [],
      "source": [
        "df['AgeGroup'] = pd.cut(df['Age'],\n",
        "                        bins=[0, 12, 18, 35, 60, 100],\n",
        "                        labels=['Child', 'Teen', 'Adult', 'Mid-Aged', 'Senior'])\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slIltN73IZVY"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[['Age', 'Fare']] = scaler.fit_transform(df[['Age', 'Fare']])\n",
        "\n",
        "print(df[['Age', 'Fare']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTzFo3bOJo9I"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv(list(uploaded.keys())[0])  # take uploaded file\n",
        "print(\" Dataset loaded successfully\")\n",
        "df.head()\n",
        "# ----- FEATURE ENGINEERING -----\n",
        "\n",
        "# 1. Create HasCabin feature\n",
        "df['HasCabin'] = df['Cabin'].notnull().astype(int)\n",
        "\n",
        "# 2. Create AgeGroup bins\n",
        "df['AgeGroup'] = pd.cut(df['Age'],\n",
        "                        bins=[0, 12, 18, 35, 50, 80],\n",
        "                        labels=['Child','Teen','YoungAdult','Adult','Senior'])\n",
        "\n",
        "# 3. Extract Title from Name\n",
        "df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "\n",
        "# 4. One-hot encode categorical features\n",
        "df = pd.get_dummies(df, columns=['Sex','Embarked','AgeGroup','Title'], drop_first=True)\n",
        "\n",
        "# 5. Define final features\n",
        "final_features = [\n",
        "    'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'HasCabin',\n",
        "    'Sex_male', 'Embarked_Q', 'Embarked_S'\n",
        "]\n",
        "\n",
        "# 6. Create feature matrix and target\n",
        "X = df[final_features]\n",
        "y = df['Survived']\n",
        "\n",
        "print(\"Features and target ready!\")\n",
        "print(\"X shape:\", X.shape)\n",
        "X.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwS6Q64wJ8li"
      },
      "source": [
        "\n",
        "\n",
        "*   As in above code 'sex' was already mapped and 'Embarked' was already encoded but since my task was to encode again so I have again redone with one-hot encoder,label encoder and columntransformer\n",
        "*   Create new features age group and titles\n",
        "*  Next we scale numerical features like age and fare, age and fare are in negative values as we have applied standardization.\n",
        "*  Then do training for the final features\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4mxJGBY_W0k"
      },
      "source": [
        "# **`Model Traning `**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qX9y2244_czi"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# Titanic Survival Prediction with Random Forest\n",
        "# ============================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# 1. Load dataset\n",
        "#df = pd.read_csv(\"/content/Titanic-Dataset.csv\")\n",
        "\n",
        "# 2. Drop irrelevant columns (not useful for prediction)\n",
        "#df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1, errors='ignore')\n",
        "\n",
        "# 3. Handle missing values\n",
        "#df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "#df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# 4. Convert categorical features into numeric\n",
        "#df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n",
        "\n",
        "# 5. Define features and target\n",
        "#X = df.drop('Survived', axis=1)\n",
        "#y = df['Survived']\n",
        "\n",
        "# 6. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 7. Random Forest Model\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=None,\n",
        "    random_state=42,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# 8. Predictions\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# 9. Evaluation\n",
        "print(\" Random Forest Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# 10. Confusion Matrix Heatmap\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Random Forest - Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# 11. Feature Importance Plot\n",
        "importances = rf_model.feature_importances_\n",
        "features = X.columns\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x=importances[indices], y=features[indices])\n",
        "plt.title(\"Feature Importances (Random Forest)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IujSYSKfHINU"
      },
      "source": [
        "Extra Detailing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7C2mb4he_fNg"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# Titanic Survival Prediction - Random Forest Classifier\n",
        "# ========================================\n",
        "\n",
        "#  Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# ========================================\n",
        "# 1. Load Dataset\n",
        "# ========================================\n",
        "df = pd.read_csv(\"/content/Titanic-Dataset.csv\")\n",
        "\n",
        "print(\" Dataset Shape:\", df.shape)\n",
        "print(\"\\n First 5 Rows of Dataset:\")\n",
        "display(df.head())\n",
        "\n",
        "# ========================================\n",
        "# 2. Data Preprocessing\n",
        "# ========================================\n",
        "\n",
        "# Drop irrelevant columns\n",
        "df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1, errors='ignore')\n",
        "\n",
        "# Handle missing values\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Feature Engineering\n",
        "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
        "df['IsAlone'] = 1 * (df['FamilySize'] == 1)\n",
        "\n",
        "# Encode categorical features\n",
        "df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n",
        "\n",
        "print(\"\\n Preprocessed Dataset Shape:\", df.shape)\n",
        "\n",
        "# ========================================\n",
        "# 3. Define Features and Target\n",
        "# ========================================\n",
        "X = df.drop('Survived', axis=1)\n",
        "y = df['Survived']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# ========================================\n",
        "# 4. Train Random Forest Model\n",
        "# ========================================\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=None,\n",
        "    random_state=42,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# ========================================\n",
        "# 5. Evaluation Metrics\n",
        "# ========================================\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nRandom Forest Evaluation Metrics:\")\n",
        "print(\"Accuracy :\", round(accuracy, 4))\n",
        "print(\"Precision:\", round(precision, 4))\n",
        "print(\"Recall   :\", round(recall, 4))\n",
        "print(\"F1-score :\", round(f1, 4))\n",
        "\n",
        "print(\"\\n Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# ========================================\n",
        "# 6. Confusion Matrix (Beautiful Plot)\n",
        "# ========================================\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap=\"YlGnBu\", cbar=False,\n",
        "            xticklabels=['Died (0)', 'Survived (1)'],\n",
        "            yticklabels=['Died (0)', 'Survived (1)'])\n",
        "plt.title(\" Random Forest - Confusion Matrix\", fontsize=14)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "# ========================================\n",
        "# 7. Feature Importance Visualization\n",
        "# ========================================\n",
        "importances = rf_model.feature_importances_\n",
        "features = X.columns\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x=importances[indices], y=features[indices], palette=\"viridis\")\n",
        "plt.title(\" Feature Importances (Random Forest)\", fontsize=14)\n",
        "plt.xlabel(\"Importance Score\")\n",
        "plt.ylabel(\"Features\")\n",
        "plt.show()\n",
        "\n",
        "# ========================================\n",
        "# 8. Cross-Validation for Stable Performance\n",
        "# ========================================\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(rf_model, X, y, cv=cv, scoring='accuracy')\n",
        "\n",
        "print(\"\\n Cross-Validation Results:\")\n",
        "print(\"All 10-Fold Scores:\", np.round(cv_scores, 4))\n",
        "print(\"Mean Accuracy:\", round(cv_scores.mean(), 4))\n",
        "print(\"Standard Deviation:\", round(cv_scores.std(), 4))\n",
        "\n",
        "# ========================================\n",
        "# 9. Extra Insight: Survival by Gender & Class\n",
        "# ========================================\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "sns.barplot(x=\"Sex_male\", y=\"Survived\", data=df)\n",
        "plt.title(\"Survival Rate by Gender\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.barplot(x=\"Pclass\", y=\"Survived\", data=df)\n",
        "plt.title(\" Survival Rate by Passenger Class\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAkuhrVZwGGt"
      },
      "source": [
        "## **Advanced Models & Comparison**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "911d27e0"
      },
      "source": [
        "## 1. Import Libraries & Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "369e2cc4"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os, warnings, time\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, RocCurveDisplay\n",
        "\n",
        "import joblib\n",
        "\n",
        "# try xgboost\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    xgb_available = True\n",
        "except Exception:\n",
        "    xgb_available = False\n",
        "\n",
        "print('XGBoost available:', xgb_available)\n",
        "\n",
        "DATA_PATH = 'Titanic-Dataset.csv'\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    raise FileNotFoundError(f\"Could not find {DATA_PATH} in the working directory. Upload the Kaggle train CSV as '{DATA_PATH}'.\")\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print('Dataset shape:', df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fc5567a"
      },
      "source": [
        "## 2. Basic Preprocessing & Feature Engineering\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57201b04"
      },
      "outputs": [],
      "source": [
        "\n",
        "def preprocess_df(df):\n",
        "    df = df.copy()\n",
        "    # Extract title\n",
        "    df['Title'] = df['Name'].str.extract(r',\\s*([^\\.]+)\\.')\n",
        "    df['Title'] = df['Title'].replace(['Lady','Countess','Capt','Col','Don','Dr','Major','Rev','Sir','Jonkheer','Dona'],'Rare')\n",
        "    df['Title'] = df['Title'].replace(['Mlle','Ms'],'Miss')\n",
        "    df['Title'] = df['Title'].replace(['Mme'],'Mrs')\n",
        "    # family features\n",
        "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
        "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
        "    return df\n",
        "\n",
        "df = preprocess_df(df)\n",
        "features = ['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked','Title','FamilySize','IsAlone']\n",
        "TARGET = 'Survived'\n",
        "X = df[features]\n",
        "y = df[TARGET]\n",
        "\n",
        "print('Features used:', features)\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b297744e"
      },
      "source": [
        "## 3. Train / Test Split\n",
        "\n",
        "Stratified split: 80% train / 20% test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbc2e541"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "print('Train:', X_train.shape, 'Test:', X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00c530fa"
      },
      "source": [
        "## 4. Preprocessing Pipelines\n",
        "\n",
        "Numeric imputation+scaling and categorical imputation+one-hot encoding using ColumnTransformer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cb26560"
      },
      "outputs": [],
      "source": [
        "\n",
        "numeric_features = ['Age','SibSp','Parch','Fare','FamilySize']\n",
        "categorical_features = ['Pclass','Sex','Embarked','Title','IsAlone']\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numeric_transformer, numeric_features),\n",
        "    ('cat', categorical_transformer, categorical_features)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3624043"
      },
      "source": [
        "## 5. Define Models & Hyperparameter Search\n",
        "\n",
        "SVM (GridSearchCV), GradientBoosting (RandomizedSearchCV), XGBoost or HistGradientBoosting (RandomizedSearchCV)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e81e1591"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier\n",
        "\n",
        "def make_pipeline(estimator):\n",
        "    return Pipeline(steps=[('preprocessor', preprocessor), ('clf', estimator)])\n",
        "\n",
        "# SVM\n",
        "svm = SVC(probability=True, random_state=42)\n",
        "svm_param_grid = {'clf__C': [0.1, 1, 10], 'clf__kernel': ['rbf','linear'], 'clf__gamma': ['scale','auto']}\n",
        "\n",
        "# Gradient Boosting (sklearn)\n",
        "gboost = GradientBoostingClassifier(random_state=42)\n",
        "gboost_param_dist = {'clf__n_estimators': [50,100,200], 'clf__learning_rate': [0.01,0.05,0.1], 'clf__max_depth': [3,4,6], 'clf__subsample':[0.6,0.8,1.0]}\n",
        "\n",
        "# XGBoost or fallback\n",
        "if xgb_available:\n",
        "    xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "    xgb_param_dist = {'clf__n_estimators':[50,100,200], 'clf__learning_rate':[0.01,0.05,0.1], 'clf__max_depth':[3,4,6], 'clf__subsample':[0.6,0.8,1.0], 'clf__colsample_bytree':[0.6,0.8,1.0]}\n",
        "else:\n",
        "    xgb = HistGradientBoostingClassifier(random_state=42)\n",
        "    xgb_param_dist = {'clf__max_iter':[50,100,200], 'clf__learning_rate':[0.01,0.05,0.1], 'clf__max_leaf_nodes':[15,31,63]}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "svm_search = GridSearchCV(make_pipeline(svm), svm_param_grid, cv=cv, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
        "gboost_search = RandomizedSearchCV(make_pipeline(gboost), gboost_param_dist, n_iter=12, cv=cv, scoring='roc_auc', random_state=42, n_jobs=-1, verbose=1)\n",
        "xgb_search = RandomizedSearchCV(make_pipeline(xgb), xgb_param_dist, n_iter=12, cv=cv, scoring='roc_auc', random_state=42, n_jobs=-1, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8402abb"
      },
      "source": [
        "## 6. Train All Models (with hyperparameter search)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6856b20"
      },
      "outputs": [],
      "source": [
        "\n",
        "searches = {'SVM': svm_search, 'GradientBoosting': gboost_search, 'XGBoost_like': xgb_search}\n",
        "fitted_models = {}\n",
        "start_all = time.time()\n",
        "for name, search in searches.items():\n",
        "    print(f\"\\n=== Training {name} ===\")\n",
        "    search.fit(X_train, y_train)\n",
        "    print('Best CV ROC AUC:', search.best_score_)\n",
        "    print('Best params:', search.best_params_)\n",
        "    fitted_models[name] = search.best_estimator_\n",
        "print('\\nTotal training time (s):', time.time()-start_all)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca41e2fd"
      },
      "source": [
        "## 7. Evaluate & Compare Models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05df79d3"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
        "results = []\n",
        "for name, model in fitted_models.items():\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:,1]\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    roc = roc_auc_score(y_test, y_proba)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print('Accuracy:', acc, 'ROC AUC:', roc)\n",
        "    print('Confusion matrix:\\n', cm)\n",
        "    # plot confusion\n",
        "    ConfusionMatrixDisplay(cm).plot(cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix - {name}')\n",
        "    plt.show()\n",
        "    # ROC\n",
        "    RocCurveDisplay.from_predictions(y_test, y_proba)\n",
        "    plt.title(f'ROC Curve - {name}')\n",
        "    plt.show()\n",
        "    results.append({'model': name, 'accuracy': acc, 'roc_auc': roc})\n",
        "\n",
        "results_df = pd.DataFrame(results).sort_values(by='roc_auc', ascending=False).reset_index(drop=True)\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaefbccb"
      },
      "source": [
        "## 8. Select Best Model & Save\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82818578"
      },
      "outputs": [],
      "source": [
        "# ==============================================\n",
        "# TITANIC SURVIVAL PREDICTOR - GRADIO APP\n",
        "# ==============================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import gradio as gr\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import socket\n",
        "from contextlib import closing\n",
        "\n",
        "# Function to find an available port\n",
        "def find_free_port(start_port=7860, end_port=7900):\n",
        "    for port in range(start_port, end_port + 1):\n",
        "        with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as sock:\n",
        "            if sock.connect_ex(('localhost', port)) != 0:\n",
        "                return port\n",
        "    return None\n",
        "\n",
        "# Create a model for demonstration\n",
        "try:\n",
        "    model = joblib.load('best_titanic_model.pkl')\n",
        "    print(\"Model loaded successfully!\")\n",
        "except:\n",
        "    print(\"Model file not found. Creating a demo model...\")\n",
        "    # Create and train a simple demo model\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    # Create some demo data for training\n",
        "    X_demo = np.array([[1, 0, 30, 0, 0, 50, 0, 0, 1],\n",
        "                       [3, 1, 25, 0, 0, 10, 1, 0, 0],\n",
        "                       [1, 0, 40, 1, 2, 100, 0, 0, 1],\n",
        "                       [2, 1, 20, 0, 0, 20, 0, 1, 0],\n",
        "                       [3, 1, 30, 2, 0, 15, 0, 0, 1]])\n",
        "    y_demo = np.array([1, 0, 1, 0, 0])\n",
        "    model.fit(X_demo, y_demo)\n",
        "\n",
        "    # Save the demo model for future use\n",
        "    joblib.dump(model, 'titanic_demo_model.joblib')\n",
        "    print(\"Demo model created and saved as 'titanic_demo_model.joblib'\")\n",
        "\n",
        "# Create preprocessing function\n",
        "def preprocess_input(pclass, sex, age, sibsp, parch, fare, embarked):\n",
        "    # Convert inputs to the format used during training\n",
        "    input_data = {\n",
        "        'Pclass': [pclass],\n",
        "        'Sex': [1 if sex == 'male' else 0],\n",
        "        'Age': [age],\n",
        "        'SibSp': [sibsp],\n",
        "        'Parch': [parch],\n",
        "        'Fare': [fare],\n",
        "        'Embarked_C': [1 if embarked == 'C' else 0],\n",
        "        'Embarked_Q': [1 if embarked == 'Q' else 0],\n",
        "        'Embarked_S': [1 if embarked == 'S' else 0]\n",
        "    }\n",
        "\n",
        "    # Create DataFrame and ensure correct column order\n",
        "    input_df = pd.DataFrame(input_data)\n",
        "    expected_columns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
        "\n",
        "    for col in expected_columns:\n",
        "        if col not in input_df.columns:\n",
        "            input_df[col] = 0\n",
        "\n",
        "    return input_df[expected_columns]\n",
        "\n",
        "# Create prediction function\n",
        "def predict_survival(pclass, sex, age, sibsp, parch, fare, embarked):\n",
        "    \"\"\"\n",
        "    Predict survival on the Titanic based on passenger details\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Preprocess the input\n",
        "        input_df = preprocess_input(pclass, sex, age, sibsp, parch, fare, embarked)\n",
        "\n",
        "        # Make prediction\n",
        "        prediction = model.predict(input_df)\n",
        "        probability = model.predict_proba(input_df)\n",
        "\n",
        "        # Format output\n",
        "        survival = \"Survived\" if prediction[0] == 1 else \"Did Not Survive\"\n",
        "        confidence = probability[0][prediction[0]] * 100\n",
        "\n",
        "        # Additional insights based on passenger characteristics\n",
        "        insights = []\n",
        "        if sex == 'female':\n",
        "            insights.append(\"• Females had higher survival rates on the Titanic.\")\n",
        "        if pclass == 1:\n",
        "            insights.append(\"• First-class passengers had better survival chances.\")\n",
        "        if age < 18:\n",
        "            insights.append(\"• Children were prioritized during evacuation.\")\n",
        "        if sibsp + parch > 0:\n",
        "            insights.append(\"• Passengers with family members had varied survival rates.\")\n",
        "\n",
        "        insights_text = \"\\n\".join(insights) if insights else \"No specific insights available for this passenger profile.\"\n",
        "\n",
        "        result = \"Prediction: \" + survival + \" (\" + str(round(confidence, 1)) + \"% confidence)\\n\\n\"\n",
        "        result += \"Additional Insights:\\n\" + insights_text\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        return \"Error making prediction: \" + str(e)\n",
        "\n",
        "# Create the Gradio interface\n",
        "title = \"Titanic Survival Predictor\"\n",
        "description = \"\"\"\n",
        "This app predicts whether a passenger would have survived the Titanic disaster based on their characteristics.\n",
        "Enter the passenger details below and click 'Predict' to see the result.\n",
        "\"\"\"\n",
        "\n",
        "examples = [\n",
        "    [1, \"female\", 29, 0, 0, 211.3375, \"S\"],  # First class female\n",
        "    [3, \"male\", 25, 0, 0, 7.8958, \"S\"],      # Third class male\n",
        "    [2, \"female\", 18, 1, 0, 23.0, \"S\"],      # Second class female with sibling\n",
        "]\n",
        "\n",
        "# Create the interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict_survival,\n",
        "    inputs=[\n",
        "        gr.Dropdown([1, 2, 3], label=\"Passenger Class\", info=\"1 = First, 2 = Second, 3 = Third\"),\n",
        "        gr.Radio([\"male\", \"female\"], label=\"Gender\"),\n",
        "        gr.Slider(0, 100, value=30, label=\"Age\"),\n",
        "        gr.Slider(0, 10, value=0, step=1, label=\"Number of Siblings/Spouses Aboard\"),\n",
        "        gr.Slider(0, 10, value=0, step=1, label=\"Number of Parents/Children Aboard\"),\n",
        "        gr.Number(value=32.0, label=\"Fare Paid (in pounds)\"),\n",
        "        gr.Radio([\"C\", \"Q\", \"S\"], label=\"Port of Embarkation\", info=\"C = Cherbourg, Q = Queenstown, S = Southampton\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Prediction Result\", lines=5),\n",
        "    title=title,\n",
        "    description=description,\n",
        "    examples=examples,\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "# Launch the application\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Launching Titanic Survival Predictor App...\")\n",
        "\n",
        "    # Find an available port\n",
        "    free_port = find_free_port(7860, 7900)\n",
        "    if free_port is None:\n",
        "        free_port = 7860  # Default if no free port found\n",
        "\n",
        "    print(f\"The app will be available at: http://localhost:{free_port}\")\n",
        "    print(\"If it doesn't open automatically, copy and paste the above URL into your browser.\")\n",
        "\n",
        "    # Launch with the available port\n",
        "    iface.launch(server_name=\"0.0.0.0\", server_port=free_port, share=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjhklYLeMP_J"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}